{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üèõÔ∏è Entrenamiento de Traductor Lat√≠n‚ÜíEspa√±ol - Fase 1\n",
                "\n",
                "## Objetivo\n",
                "Entrenar un modelo mT5-small para traducir lat√≠n cl√°sico a espa√±ol.\n",
                "\n",
                "**Fase 1**: Modelo base con ~30,000 pares (BLEU esperado: ~30-35)\n",
                "\n",
                "---\n",
                "\n",
                "## ‚öôÔ∏è Configuraci√≥n Inicial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 1: CONEXI√ìN A GOOGLE DRIVE\n",
                "# ============================================\n",
                "# ¬øPor qu√©? Para guardar checkpoints y no perder progreso\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Crear directorio de trabajo\n",
                "!mkdir -p /content/drive/MyDrive/latin_translator_phase1\n",
                "%cd /content/drive/MyDrive/latin_translator_phase1\n",
                "\n",
                "print(\"‚úÖ Google Drive conectado\")\n",
                "print(\"üìÅ Directorio: /content/drive/MyDrive/latin_translator_phase1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 2: INSTALACI√ìN DE DEPENDENCIAS\n",
                "# ============================================\n",
                "\n",
                "!pip install -q transformers datasets sentencepiece sacrebleu accelerate\n",
                "\n",
                "print(\"‚úÖ Dependencias instaladas\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 3: VERIFICACI√ìN DE GPU\n",
                "# ============================================\n",
                "\n",
                "import torch\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"‚úÖ GPU disponible: {gpu_name}\")\n",
                "    print(f\"üíæ Memoria GPU: {gpu_memory:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ùå GPU no disponible\")\n",
                "    print(\"‚ö†Ô∏è Ve a: Runtime > Change runtime type > GPU (T4)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìä Preparaci√≥n de Datos\n",
                "\n",
                "Vamos a usar m√∫ltiples fuentes para el corpus de Fase 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 4: DESCARGA DE CORPUS\n",
                "# ============================================\n",
                "# Usaremos el corpus OPUS que tiene pares lat√≠n-espa√±ol\n",
                "\n",
                "import json\n",
                "import requests\n",
                "from pathlib import Path\n",
                "\n",
                "# Crear directorio de datos\n",
                "!mkdir -p data\n",
                "\n",
                "# Opci√≥n 1: Subir tus propios datos\n",
                "print(\"üì§ OPCI√ìN 1: Sube tus archivos train.json y validation.json\")\n",
                "print(\"   (Si ya los tienes preparados localmente)\")\n",
                "print()\n",
                "print(\"üì• OPCI√ìN 2: Usar datos de ejemplo\")\n",
                "print(\"   (Continuaremos con datos m√≠nimos para probar)\")\n",
                "\n",
                "# Datos de ejemplo (classical samples)\n",
                "example_data = [\n",
                "    {\"latin\": \"Gallia est omnis divisa in partes tres.\", \n",
                "     \"spanish\": \"Toda la Galia est√° dividida en tres partes.\"},\n",
                "    {\"latin\": \"Veni, vidi, vici.\", \n",
                "     \"spanish\": \"Vine, vi, venc√≠.\"},\n",
                "    {\"latin\": \"Alea iacta est.\", \n",
                "     \"spanish\": \"La suerte est√° echada.\"},\n",
                "    {\"latin\": \"Carpe diem.\", \n",
                "     \"spanish\": \"Aprovecha el d√≠a.\"},\n",
                "    {\"latin\": \"Errare humanum est.\", \n",
                "     \"spanish\": \"Errar es humano.\"},\n",
                "]\n",
                "\n",
                "# Guardar datos de ejemplo\n",
                "with open('data/example_train.json', 'w', encoding='utf-8') as f:\n",
                "    json.dump(example_data * 100, f, ensure_ascii=False, indent=2)  # Repetir para tener m√°s datos\n",
                "\n",
                "with open('data/example_validation.json', 'w', encoding='utf-8') as f:\n",
                "    json.dump(example_data[:2], f, ensure_ascii=False, indent=2)\n",
                "\n",
                "print(\"‚úÖ Datos de ejemplo creados\")\n",
                "print(\"‚ö†Ô∏è IMPORTANTE: Para entrenamiento real, necesitas subir corpus m√°s grande\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 5: CARGAR DATOS\n",
                "# ============================================\n",
                "\n",
                "from datasets import Dataset, DatasetDict\n",
                "\n",
                "def load_data(train_path='data/train.json', val_path='data/validation.json'):\n",
                "    \"\"\"\n",
                "    Carga datos de entrenamiento y validaci√≥n.\n",
                "    Si no existen, usa los de ejemplo.\n",
                "    \"\"\"\n",
                "    # Intentar cargar datos reales\n",
                "    try:\n",
                "        with open(train_path, 'r', encoding='utf-8') as f:\n",
                "            train_data = json.load(f)\n",
                "        with open(val_path, 'r', encoding='utf-8') as f:\n",
                "            val_data = json.load(f)\n",
                "        print(\"‚úÖ Datos personalizados cargados\")\n",
                "    except FileNotFoundError:\n",
                "        print(\"‚ö†Ô∏è Usando datos de ejemplo\")\n",
                "        with open('data/example_train.json', 'r', encoding='utf-8') as f:\n",
                "            train_data = json.load(f)\n",
                "        with open('data/example_validation.json', 'r', encoding='utf-8') as f:\n",
                "            val_data = json.load(f)\n",
                "    \n",
                "    # Convertir a Dataset\n",
                "    train_dataset = Dataset.from_dict({\n",
                "        'latin': [item['latin'] for item in train_data],\n",
                "        'spanish': [item['spanish'] for item in train_data]\n",
                "    })\n",
                "    \n",
                "    val_dataset = Dataset.from_dict({\n",
                "        'latin': [item['latin'] for item in val_data],\n",
                "        'spanish': [item['spanish'] for item in val_data]\n",
                "    })\n",
                "    \n",
                "    return DatasetDict({\n",
                "        'train': train_dataset,\n",
                "        'validation': val_dataset\n",
                "    })\n",
                "\n",
                "# Cargar datos\n",
                "dataset = load_data()\n",
                "\n",
                "print(f\"\\nüìä Estad√≠sticas:\")\n",
                "print(f\"   - Entrenamiento: {len(dataset['train'])} pares\")\n",
                "print(f\"   - Validaci√≥n: {len(dataset['validation'])} pares\")\n",
                "print(f\"\\nüìù Ejemplo:\")\n",
                "print(f\"   Latin: {dataset['train'][0]['latin']}\")\n",
                "print(f\"   Spanish: {dataset['train'][0]['spanish']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ü§ñ Configuraci√≥n del Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 6: CARGAR MODELO mT5-small\n",
                "# ============================================\n",
                "\n",
                "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
                "\n",
                "MODEL_NAME = \"google/mt5-small\"\n",
                "\n",
                "print(f\"üì• Cargando modelo: {MODEL_NAME}\")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
                "\n",
                "print(f\"‚úÖ Modelo cargado\")\n",
                "print(f\"üìä Par√°metros: {model.num_parameters():,}\")\n",
                "print(f\"üíæ Tama√±o aproximado: ~300MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 7: PREPROCESAMIENTO\n",
                "# ============================================\n",
                "\n",
                "def preprocess_function(examples):\n",
                "    \"\"\"\n",
                "    Preprocesa los datos para mT5.\n",
                "    A√±ade prefijo de tarea y tokeniza.\n",
                "    \"\"\"\n",
                "    # Prefijo de tarea\n",
                "    inputs = [\"translate Latin to Spanish: \" + text for text in examples['latin']]\n",
                "    targets = examples['spanish']\n",
                "    \n",
                "    # Tokenizar\n",
                "    model_inputs = tokenizer(\n",
                "        inputs,\n",
                "        max_length=128,\n",
                "        truncation=True,\n",
                "        padding='max_length'\n",
                "    )\n",
                "    \n",
                "    labels = tokenizer(\n",
                "        targets,\n",
                "        max_length=128,\n",
                "        truncation=True,\n",
                "        padding='max_length'\n",
                "    )\n",
                "    \n",
                "    model_inputs['labels'] = labels['input_ids']\n",
                "    \n",
                "    return model_inputs\n",
                "\n",
                "# Aplicar preprocesamiento\n",
                "print(\"üîÑ Preprocesando datos...\")\n",
                "tokenized_dataset = dataset.map(\n",
                "    preprocess_function,\n",
                "    batched=True,\n",
                "    remove_columns=dataset['train'].column_names\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Datos preprocesados\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéØ Entrenamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 8: CONFIGURACI√ìN DE ENTRENAMIENTO\n",
                "# ============================================\n",
                "\n",
                "from transformers import TrainingArguments, Trainer\n",
                "import numpy as np\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    # Directorio de salida (en Google Drive)\n",
                "    output_dir=\"./checkpoints\",\n",
                "    \n",
                "    # Guardado de checkpoints\n",
                "    save_strategy=\"steps\",\n",
                "    save_steps=500,\n",
                "    save_total_limit=3,  # Mantener solo √∫ltimos 3\n",
                "    \n",
                "    # Evaluaci√≥n\n",
                "    evaluation_strategy=\"steps\",\n",
                "    eval_steps=500,\n",
                "    \n",
                "    # Hiperpar√°metros\n",
                "    learning_rate=5e-5,\n",
                "    per_device_train_batch_size=8,\n",
                "    per_device_eval_batch_size=8,\n",
                "    num_train_epochs=3,\n",
                "    \n",
                "    # Optimizaciones\n",
                "    fp16=True,  # Precisi√≥n mixta\n",
                "    gradient_accumulation_steps=2,\n",
                "    \n",
                "    # Logging\n",
                "    logging_dir=\"./logs\",\n",
                "    logging_steps=100,\n",
                "    \n",
                "    # Otros\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=\"eval_loss\",\n",
                "    report_to=\"none\"\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Configuraci√≥n de entrenamiento lista\")\n",
                "print(f\"\\nüìä Par√°metros:\")\n",
                "print(f\"   - √âpocas: {training_args.num_train_epochs}\")\n",
                "print(f\"   - Learning rate: {training_args.learning_rate}\")\n",
                "print(f\"   - Batch size: {training_args.per_device_train_batch_size}\")\n",
                "print(f\"   - Checkpoints cada: {training_args.save_steps} pasos\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 9: M√âTRICAS\n",
                "# ============================================\n",
                "\n",
                "from datasets import load_metric\n",
                "\n",
                "metric = load_metric(\"sacrebleu\")\n",
                "\n",
                "def compute_metrics(eval_preds):\n",
                "    \"\"\"\n",
                "    Calcula BLEU score.\n",
                "    \"\"\"\n",
                "    preds, labels = eval_preds\n",
                "    \n",
                "    # Decodificar\n",
                "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
                "    \n",
                "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
                "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
                "    \n",
                "    # BLEU\n",
                "    result = metric.compute(\n",
                "        predictions=decoded_preds,\n",
                "        references=[[label] for label in decoded_labels]\n",
                "    )\n",
                "    \n",
                "    return {\"bleu\": result[\"score\"]}\n",
                "\n",
                "print(\"‚úÖ M√©tricas configuradas\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 10: INICIAR ENTRENAMIENTO\n",
                "# ============================================\n",
                "\n",
                "import os\n",
                "\n",
                "# Verificar checkpoints existentes\n",
                "checkpoints = [d for d in os.listdir(\"./checkpoints\") if d.startswith(\"checkpoint-\")] if os.path.exists(\"./checkpoints\") else []\n",
                "\n",
                "if checkpoints:\n",
                "    latest = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[1]))[-1]\n",
                "    checkpoint_path = f\"./checkpoints/{latest}\"\n",
                "    print(f\"üîÑ Reanudando desde: {checkpoint_path}\")\n",
                "    resume_from = checkpoint_path\n",
                "else:\n",
                "    print(\"üÜï Iniciando entrenamiento desde cero\")\n",
                "    resume_from = None\n",
                "\n",
                "# Crear Trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_dataset['train'],\n",
                "    eval_dataset=tokenized_dataset['validation'],\n",
                "    tokenizer=tokenizer,\n",
                "    compute_metrics=compute_metrics\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\n‚è±Ô∏è Tiempo estimado: 8-12 horas (para corpus completo)\")\n",
                "print(\"üíæ Checkpoints se guardan cada 500 pasos en Google Drive\")\n",
                "print(\"üîÑ Puedes cerrar esta pesta√±a - el progreso se guarda\")\n",
                "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
                "\n",
                "# ENTRENAR\n",
                "trainer.train(resume_from_checkpoint=resume_from)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 11: GUARDAR MODELO FINAL\n",
                "# ============================================\n",
                "\n",
                "trainer.save_model(\"./final_model\")\n",
                "tokenizer.save_pretrained(\"./final_model\")\n",
                "\n",
                "print(\"‚úÖ Modelo final guardado en: ./final_model\")\n",
                "print(\"\\nüì• Para descargar:\")\n",
                "print(\"   1. Ve a Google Drive\")\n",
                "print(\"   2. Navega a: MyDrive/latin_translator_phase1/final_model\")\n",
                "print(\"   3. Descarga la carpeta completa\")\n",
                "print(\"   4. Col√≥cala en tu proyecto: models/latin_translator_v1.0\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üß™ Pruebas del Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 12: PROBAR TRADUCCIONES\n",
                "# ============================================\n",
                "\n",
                "def translate(latin_text, model_path=\"./final_model\"):\n",
                "    \"\"\"\n",
                "    Traduce texto latino a espa√±ol.\n",
                "    \"\"\"\n",
                "    input_text = f\"translate Latin to Spanish: {latin_text}\"\n",
                "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=128, truncation=True).to(model.device)\n",
                "    \n",
                "    outputs = model.generate(\n",
                "        **inputs,\n",
                "        max_length=128,\n",
                "        num_beams=4,\n",
                "        early_stopping=True\n",
                "    )\n",
                "    \n",
                "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    return translation\n",
                "\n",
                "# Probar con ejemplos\n",
                "test_sentences = [\n",
                "    \"Gallia est omnis divisa in partes tres.\",\n",
                "    \"Veni, vidi, vici.\",\n",
                "    \"Alea iacta est.\",\n",
                "    \"Carpe diem.\"\n",
                "]\n",
                "\n",
                "print(\"üß™ Probando traducciones:\\n\")\n",
                "for latin in test_sentences:\n",
                "    spanish = translate(latin)\n",
                "    print(f\"Latin:   {latin}\")\n",
                "    print(f\"Spanish: {spanish}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìä Evaluaci√≥n Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SECCI√ìN 13: EVALUACI√ìN FINAL\n",
                "# ============================================\n",
                "\n",
                "# Evaluar en conjunto de validaci√≥n\n",
                "eval_results = trainer.evaluate()\n",
                "\n",
                "print(\"üìä Resultados Finales:\")\n",
                "print(f\"   - Loss: {eval_results['eval_loss']:.4f}\")\n",
                "print(f\"   - BLEU: {eval_results['eval_bleu']:.2f}\")\n",
                "print()\n",
                "print(\"üéØ Interpretaci√≥n:\")\n",
                "if eval_results['eval_bleu'] > 40:\n",
                "    print(\"   ‚úÖ Excelente calidad\")\n",
                "elif eval_results['eval_bleu'] > 30:\n",
                "    print(\"   ‚úÖ Buena calidad\")\n",
                "elif eval_results['eval_bleu'] > 20:\n",
                "    print(\"   ‚ö†Ô∏è Calidad aceptable - considera Fase 2\")\n",
                "else:\n",
                "    print(\"   ‚ùå Calidad baja - necesitas m√°s datos\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéâ ¬°Entrenamiento Completado!\n",
                "\n",
                "### Pr√≥ximos Pasos:\n",
                "\n",
                "1. **Descargar modelo**: Descarga la carpeta `final_model` de Google Drive\n",
                "2. **Integrar en aplicaci√≥n**: Coloca el modelo en tu proyecto local\n",
                "3. **Evaluar calidad**: Prueba con textos reales\n",
                "4. **Fase 2** (opcional): Si necesitas mejor calidad, contin√∫a entrenamiento con m√°s datos\n",
                "\n",
                "### Informaci√≥n del Modelo:\n",
                "\n",
                "- **Nombre**: `latin_translator_v1.0`\n",
                "- **Arquitectura**: mT5-small\n",
                "- **Tama√±o**: ~300MB\n",
                "- **Datos de entrenamiento**: Fase 1\n",
                "- **BLEU score**: (ver arriba)\n",
                "\n",
                "---\n",
                "\n",
                "**¬øPreguntas?** Revisa la gu√≠a en `docs/ai_training_guide.md`"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}