"""
Script para extraer y alinear frases de textos biling√ºes.

√ötil para preparar corpus de entrenamiento a partir de ediciones biling√ºes
de obras cl√°sicas (ej: lat√≠n-espa√±ol, lat√≠n-italiano).
"""

import re
from pathlib import Path
from typing import List, Tuple
import json

def split_into_sentences(text: str) -> List[str]:
    """
    Divide texto en oraciones.
    
    Heur√≠stica simple: dividir por puntos, signos de exclamaci√≥n, interrogaci√≥n.
    Ajusta seg√∫n tus textos.
    """
    # Dividir por . ! ? seguido de may√∫scula o fin de l√≠nea
    sentences = re.split(r'(?<=[.!?])\s+(?=[A-Z])', text)
    
    # Limpiar espacios
    sentences = [s.strip() for s in sentences if s.strip()]
    
    return sentences

def align_parallel_text(
    latin_text: str,
    translation_text: str,
    language: str = "Spanish"
) -> List[dict]:
    """
    Alinea texto latino con su traducci√≥n.
    
    ASUME que ambos textos tienen el mismo n√∫mero de oraciones
    y est√°n correctamente alineadas (misma oraci√≥n en misma posici√≥n).
    
    Args:
        latin_text: Texto completo en lat√≠n
        translation_text: Traducci√≥n completa
        language: "Spanish" o "Italian"
    
    Returns:
        Lista de pares {"latin": "...", "spanish/italian": "..."}
    """
    
    latin_sentences = split_into_sentences(latin_text)
    trans_sentences = split_into_sentences(translation_text)
    
    # Verificar alineaci√≥n
    if len(latin_sentences) != len(trans_sentences):
        print(f"‚ö†Ô∏è ADVERTENCIA: Desalineaci√≥n detectada")
        print(f"   Lat√≠n: {len(latin_sentences)} oraciones")
        print(f"   {language}: {len(trans_sentences)} oraciones")
        print()
        
        # Usar el m√≠nimo para evitar errores
        min_len = min(len(latin_sentences), len(trans_sentences))
        latin_sentences = latin_sentences[:min_len]
        trans_sentences = trans_sentences[:min_len]
        
        print(f"   Usando solo las primeras {min_len} oraciones alineadas")
        print()
    
    # Crear pares
    pairs = []
    lang_key = language.lower()
    
    for lat, trans in zip(latin_sentences, trans_sentences):
        pairs.append({
            "latin": lat,
            lang_key: trans
        })
    
    return pairs

def load_parallel_files(
    latin_file: Path,
    translation_file: Path,
    language: str = "Spanish"
) -> List[dict]:
    """
    Carga textos paralelos desde archivos y los alinea.
    """
    
    print(f"üìñ Procesando: {latin_file.name}")
    
    with open(latin_file, 'r', encoding='utf-8') as f:
        latin_text = f.read()
    
    with open(translation_file, 'r', encoding='utf-8') as f:
        trans_text = f.read()
    
    pairs = align_parallel_text(latin_text, trans_text, language)
    
    print(f"   ‚úÖ Extra√≠dos: {len(pairs)} pares")
    
    return pairs

def process_multiple_works(
    works_config: List[dict],
    output_file: Path
):
    """
    Procesa m√∫ltiples obras y las combina.
    
    Args:
        works_config: Lista de configuraciones, cada una con:
            {
                "latin_file": "path/to/latin.txt",
                "translation_file": "path/to/translation.txt",
                "language": "Spanish" o "Italian"
            }
        output_file: Archivo de salida JSON
    """
    
    all_pairs = []
    
    for work in works_config:
        pairs = load_parallel_files(
            Path(work["latin_file"]),
            Path(work["translation_file"]),
            work["language"]
        )
        all_pairs.extend(pairs)
    
    # Guardar
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_pairs, f, ensure_ascii=False, indent=2)
    
    # Estad√≠sticas
    spanish_count = sum(1 for p in all_pairs if 'spanish' in p)
    italian_count = sum(1 for p in all_pairs if 'italian' in p)
    
    print()
    print("=" * 60)
    print("‚úÖ RESUMEN")
    print("=" * 60)
    print(f"Total de pares: {len(all_pairs)}")
    print(f"  - Lat√≠n-Espa√±ol: {spanish_count}")
    print(f"  - Lat√≠n-Italiano: {italian_count}")
    print()
    print(f"Guardado en: {output_file}")
    print()

# ============================================
# EJEMPLO DE USO
# ============================================

if __name__ == "__main__":
    
    print("=" * 60)
    print("EXTRACTOR DE TEXTOS PARALELOS")
    print("=" * 60)
    print()
    
    # OPCI√ìN 1: Una sola obra
    print("OPCI√ìN 1: Procesar una obra biling√ºe")
    print("-" * 60)
    print()
    
    # Ejemplo: De Bello Gallico (lat√≠n-espa√±ol)
    # Ajusta las rutas a tus archivos reales
    
    # pairs = load_parallel_files(
    #     latin_file=Path("data/texts/caesar_gallico_la.txt"),
    #     translation_file=Path("data/texts/caesar_gallico_es.txt"),
    #     language="Spanish"
    # )
    # 
    # with open("data/corpus/caesar_es.json", "w", encoding="utf-8") as f:
    #     json.dump(pairs, f, ensure_ascii=False, indent=2)
    
    print("Descomenta el c√≥digo y ajusta las rutas")
    print()
    
    # OPCI√ìN 2: M√∫ltiples obras mezcladas
    print("OPCI√ìN 2: Procesar m√∫ltiples obras")
    print("-" * 60)
    print()
    
    # Configuraci√≥n de ejemplo
    works_config = [
        # Obras en espa√±ol
        {
            "latin_file": "data/texts/caesar_la.txt",
            "translation_file": "data/texts/caesar_es.txt",
            "language": "Spanish"
        },
        {
            "latin_file": "data/texts/virgilio_la.txt",
            "translation_file": "data/texts/virgilio_es.txt",
            "language": "Spanish"
        },
        
        # Obras en italiano
        {
            "latin_file": "data/texts/ovidio_la.txt",
            "translation_file": "data/texts/ovidio_it.txt",
            "language": "Italian"
        },
        {
            "latin_file": "data/texts/ciceron_la.txt",
            "translation_file": "data/texts/ciceron_it.txt",
            "language": "Italian"
        }
    ]
    
    # Descomentar para usar:
    # process_multiple_works(
    #     works_config=works_config,
    #     output_file=Path("data/corpus/mixed_multilingual.json")
    # )
    
    print("Configuraci√≥n de ejemplo preparada")
    print()
    print("=" * 60)
    print("üìã INSTRUCCIONES")
    print("=" * 60)
    print()
    print("1. **Organiza tus textos:**")
    print()
    print("   data/texts/")
    print("   ‚îú‚îÄ‚îÄ obra1_latino.txt       # C√©sar en lat√≠n")
    print("   ‚îú‚îÄ‚îÄ obra1_espa√±ol.txt      # C√©sar en espa√±ol")
    print("   ‚îú‚îÄ‚îÄ obra2_latino.txt       # Virgilio en lat√≠n")
    print("   ‚îú‚îÄ‚îÄ obra2_italiano.txt     # Virgilio en italiano")
    print("   ‚îî‚îÄ‚îÄ ...")
    print()
    print("2. **Verifica alineaci√≥n:**")
    print("   - Cada archivo debe tener UNA ORACI√ìN POR P√ÅRRAFO")
    print("   - O bien, oraciones separadas por punto+may√∫scula")
    print("   - La oraci√≥n 1 del latino = oraci√≥n 1 de la traducci√≥n")
    print()
    print("3. **Edita la configuraci√≥n en este script:**")
    print("   - Ajusta works_config con tus archivos reales")
    print("   - Especifica el idioma de cada obra")
    print()
    print("4. **Ejecuta:**")
    print("   python scripts//home/diego/Projects/latin-python/test_debug_scripts/extract_parallel_texts.py")
    print()
    print("5. **Resultado:**")
    print("   data/corpus/mixed_multilingual.json")
    print()
    print("6. **Usa con prepare_multilingual_corpus.py:**")
    print("   El JSON generado ya est√° listo para convertir al")
    print("   formato de entrenamiento con prefijos.")
    print()
    
    # OPCI√ìN 3: An√°lisis de alineaci√≥n
    print()
    print("OPCI√ìN 3: Verificar alineaci√≥n de un texto")
    print("-" * 60)
    print()
    
    def verify_alignment(latin_file: Path, trans_file: Path):
        """Muestra primeras 5 oraciones para verificar alineaci√≥n."""
        
        with open(latin_file, 'r', encoding='utf-8') as f:
            latin_text = f.read()
        
        with open(trans_file, 'r', encoding='utf-8') as f:
            trans_text = f.read()
        
        latin_sentences = split_into_sentences(latin_text)
        trans_sentences = split_into_sentences(trans_text)
        
        print(f"Archivo latino: {latin_file.name}")
        print(f"Archivo traducci√≥n: {trans_file.name}")
        print()
        print(f"Total oraciones latino: {len(latin_sentences)}")
        print(f"Total oraciones traducci√≥n: {len(trans_sentences)}")
        print()
        
        if len(latin_sentences) != len(trans_sentences):
            print("‚ö†Ô∏è ADVERTENCIA: N√∫meros diferentes - revisar alineaci√≥n")
        else:
            print("‚úÖ Mismo n√∫mero de oraciones")
        
        print()
        print("Primeras 5 oraciones:")
        print("-" * 60)
        
        for i in range(min(5, len(latin_sentences), len(trans_sentences))):
            print(f"\n{i+1}.")
            print(f"LA: {latin_sentences[i][:80]}...")
            print(f"TR: {trans_sentences[i][:80]}...")
    
    # Descomentar para verificar un texto:
    # verify_alignment(
    #     Path("data/texts/cesar_la.txt"),
    #     Path("data/texts/cesar_es.txt")
    # )
    
    print("Usa verify_alignment() para revisar tus textos")
    print()
