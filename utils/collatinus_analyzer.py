"""
Adaptador para PyCollatinus (Motor de morfolog√≠a latina)

Este m√≥dulo proporciona una interfaz de alto nivel para PyCollatinus,
manejando la carga eficiente del modelo (Singleton), la traducci√≥n
de etiquetas del franc√©s al espa√±ol y la simplificaci√≥n de la salida.
"""

import os
import pickle
import sys
from typing import List, Dict, Optional, Any

# Intentar importar pycollatinus, manejar error si no est√° instalado
# Intentar importar pycollatinus, manejar error si no est√° instalado
try:
    # Parche para compatibilidad con Python 3.10+ (pycollatinus usa collections.Callable)
    import collections
    import collections.abc
    if not hasattr(collections, 'Callable'):
        collections.Callable = collections.abc.Callable

    from pycollatinus import Lemmatiseur
    PYCOLLATINUS_AVAILABLE = True
except ImportError:
    PYCOLLATINUS_AVAILABLE = False

class LatinMorphAnalyzer:
    """
    Wrapper para el lemmatizador de Collatinus.
    Implementa patr√≥n Singleton para cargar los datos una sola vez.
    """
    _instance = None
    _analyzer = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LatinMorphAnalyzer, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        # Evitar re-inicializaci√≥n si ya existe
        if self._analyzer is not None:
            return

        if not PYCOLLATINUS_AVAILABLE:
            print("‚ö†Ô∏è PyCollatinus no est√° instalado. Funcionalidad limitada.")
            return

        try:
            # Intentar cargar versi√≥n compilada primero (m√°s r√°pido ~3s vs ~5s)
            compiled_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'collatinus_compiled.pickle')
            
            if os.path.exists(compiled_path):
                print(f"üì¶ Cargando PyCollatinus compilado desde {compiled_path}...")
                try:
                    self._analyzer = Lemmatiseur.load(compiled_path)
                    print("‚úÖ PyCollatinus compilado cargado exitosamente")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error cargando versi√≥n compilada: {e}")
                    print("Cargando versi√≥n est√°ndar...")
                    self._analyzer = Lemmatiseur()
            else:
                print("üìö Cargando PyCollatinus (primera vez, puede tardar unos segundos)...")
                self._analyzer = Lemmatiseur()
                
                # Compilar para futuras cargas
                print("üîß Compilando PyCollatinus para futuras cargas...")
                try:
                    os.makedirs(os.path.dirname(compiled_path), exist_ok=True)
                    # compile() no acepta argumentos, guarda en su propia ubicaci√≥n
                    self._analyzer.compile()
                    # Intentar copiar el archivo compilado a nuestra ubicaci√≥n
                    import shutil
                    default_compiled = self._analyzer.path('compiled.pickle')
                    if os.path.exists(default_compiled):
                        shutil.copy(default_compiled, compiled_path)
                        print(f"‚úÖ PyCollatinus compilado guardado en {compiled_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è No se pudo compilar: {e}")

            
            # Mapeo de traducci√≥n Franc√©s -> Espa√±ol
            self.translations = {
                # Casos
                'nominatif': 'Nominativo',
                'vocatif': 'Vocativo',
                'accusatif': 'Acusativo',
                'g√©nitif': 'Genitivo',
                'datif': 'Dativo',
                'ablatif': 'Ablativo',
                'locatif': 'Locativo',
                
                # N√∫meros
                'singulier': 'Singular',
                'pluriel': 'Plural',
                
                # G√©neros
                'masculin': 'Masculino',
                'f√©minin': 'Femenino',
                'neutre': 'Neutro',
                
                # Personas
                '1√®re': '1¬™ Persona',
                '2√®me': '2¬™ Persona',
                '3√®me': '3¬™ Persona',
                
                # Tiempos
                'pr√©sent': 'Presente',
                'imparfait': 'Imperfecto',
                'futur': 'Futuro',
                'parfait': 'Perfecto',
                'plus-que-parfait': 'Pluscuamperfecto',
                'futur ant√©rieur': 'Futuro Perfecto',
                
                # Modos
                'indicatif': 'Indicativo',
                'subjonctif': 'Subjuntivo',
                'imp√©ratif': 'Imperativo',
                'infinitif': 'Infinitivo',
                'participe': 'Participio',
                'g√©rondif': 'Gerundio',
                'supin': 'Supino',
                
                # Voces
                'actif': 'Activa',
                'passif': 'Pasiva',
                'd√©ponent': 'Deponente',
                
                # Grados
                'positif': 'Positivo',
                'comparatif': 'Comparativo',
                'superlatif': 'Superlativo',
                
                # Otros
                'adjectif': 'Adjetivo',
                'adverbe': 'Adverbio',
                'pr√©position': 'Preposici√≥n',
                'conjonction': 'Conjunci√≥n',
                'interjection': 'Interjecci√≥n',
                'num√©ral': 'Numeral',
                'pronom': 'Pronombre',
            }
            
        except Exception as e:
            print(f"‚ùå Error inicializando PyCollatinus: {e}")
            self._analyzer = None

    def is_ready(self) -> bool:
        """Verifica si el analizador est√° listo para usarse"""
        return self._analyzer is not None

    def _translate_morph(self, morph_str: str) -> str:
        """Traduce la cadena de morfolog√≠a del franc√©s al espa√±ol"""
        if not morph_str:
            return ""
            
        words = morph_str.split()
        translated_words = []
        
        for word in words:
            # Limpiar puntuaci√≥n si es necesario, aunque Collatinus suele dar limpio
            clean_word = word.lower()
            if clean_word in self.translations:
                translated_words.append(self.translations[clean_word])
            else:
                # Mantener palabra original si no hay traducci√≥n (ej. palabras desconocidas)
                translated_words.append(word)
                
        return " ".join(translated_words)

    def analyze_word(self, word: str) -> List[Dict[str, Any]]:
        """
        Analiza una palabra latina y devuelve todas sus posibles formas.
        
        Args:
            word: Palabra en lat√≠n
            
        Returns:
            Lista de diccionarios con lema, morfolog√≠a (traducida) y detalles
        """
        if not self.is_ready():
            return []
            
        try:
            raw_results = self._analyzer.lemmatise(word)
            processed_results = []
            
            for res in raw_results:
                processed_results.append({
                    'lemma': res.get('lemma', ''),
                    'morph_raw': res.get('morph', ''),
                    'morph': self._translate_morph(res.get('morph', '')),
                    'radical': res.get('radical', ''),
                    'desinence': res.get('desinence', '')
                })
                
            return processed_results
            
        except Exception as e:
            print(f"Error analizando '{word}': {e}")
            return []

    def analyze_phrase(self, phrase: str) -> List[Dict[str, Any]]:
        """
        Analiza una frase completa token por token.
        
        Args:
            phrase: Frase en lat√≠n
            
        Returns:
            Lista de resultados por palabra
        """
        if not self.is_ready():
            return []
            
        try:
            # Collatinus tiene lemmatise_multiple para frases
            raw_results_list = self._analyzer.lemmatise_multiple(phrase)
            words = phrase.split() # Tokenizaci√≥n simple de Collatinus
            
            final_output = []
            
            for i, word_results in enumerate(raw_results_list):
                word_text = words[i] if i < len(words) else "?"
                
                word_analyses = []
                for res in word_results:
                    word_analyses.append({
                        'lemma': res.get('lemma', ''),
                        'morph': self._translate_morph(res.get('morph', '')),
                        'raw': res
                    })
                
                final_output.append({
                    'word': word_text,
                    'analyses': word_analyses
                })
                
            return final_output
            
        except Exception as e:
            print(f"Error analizando frase: {e}")
            return []

    def generate_paradigm(self, word: str) -> Dict[str, Any]:
        """
        Genera el paradigma completo (tabla de conjugaci√≥n/declinaci√≥n) para una palabra.
        
        Args:
            word: Palabra en lat√≠n (lema)
            
        Returns:
            Diccionario con:
                - lemma: el lema
                - model: nombre del modelo de flexi√≥n
                - forms: lista de todas las formas con morfolog√≠a traducida
        """
        if not self.is_ready():
            return {}
            
        try:
            # Obtener el objeto Lemme
            lemma_obj = self._analyzer.lemme(word)
            if not lemma_obj:
                return {'error': f"Lema '{word}' no encontrado"}
            
            # Obtener el modelo de flexi√≥n
            model = lemma_obj.modele()
            
            # Obtener todas las desinencias
            desinences = model.desinences()
            
            forms = []
            
            for d in desinences:
                # Obtener el sufijo
                suffix = d.gr()
                
                # Obtener el √≠ndice del radical
                rad_idx = d.numRad()
                
                # Obtener el ID de morfolog√≠a
                morph_id = d.morphoNum()
                
                # Obtener el radical
                radicals = lemma_obj.radical(rad_idx)
                if radicals:
                    stem = radicals[0].gr()
                else:
                    stem = ""
                
                # Construir la forma completa
                full_form = stem + suffix
                
                # Obtener y traducir la morfolog√≠a
                morph_raw = self._analyzer.morpho(morph_id)
                morph_translated = self._translate_morph(morph_raw)
                
                forms.append({
                    'form': full_form,
                    'morph': morph_translated,
                    'morph_raw': morph_raw,
                    'stem': stem,
                    'suffix': suffix
                })
            
            return {
                'lemma': word,
                'model': str(model),
                'total_forms': len(forms),
                'forms': forms
            }
            
        except Exception as e:
            print(f"Error generando paradigma para '{word}': {e}")
            return {'error': str(e)}

# Instancia global para uso f√°cil
analyzer = LatinMorphAnalyzer()
