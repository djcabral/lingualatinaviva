# ğŸ“¦ Archivos de Entrenamiento Preparados

## âœ… Lo que ya tienes

He generado los archivos de entrenamiento en:
```
data/training_corpus/phase1/
â”œâ”€â”€ train.json          (916 pares)
â”œâ”€â”€ validation.json     (102 pares)
â””â”€â”€ stats.json          (estadÃ­sticas)
```

**Total: 1,018 pares latÃ­n-espaÃ±ol**

---

## ğŸ“Š Contenido Actual

### Fuentes:
- **Vulgata**: 1,000 versÃ­culos (datos de ejemplo)
- **Classical samples**: 18 pares (Caesar, Phaedrus, Eutropius)

### Formato:
```json
[
  {
    "latin": "In principio creavit Deus caelum et terram.",
    "spanish": "En el principio creÃ³ Dios los cielos y la tierra.",
    "source": "vulgata_gen_1_1",
    "difficulty": 3
  },
  ...
]
```

---

## ğŸš€ CÃ³mo Usar en Google Colab

### OpciÃ³n 1: Subir Archivos Manualmente

1. Abre el notebook en Colab
2. En la secciÃ³n "SECCIÃ“N 4: DESCARGA DE CORPUS"
3. Click en el Ã­cono de carpeta (ğŸ“) en el panel izquierdo
4. Crea carpeta `data/`
5. Sube `train.json` y `validation.json`

### OpciÃ³n 2: Subir desde Google Drive

1. Copia la carpeta `data/training_corpus/phase1/` a tu Google Drive
2. En Colab, despuÃ©s de montar Drive:
   ```python
   # Copiar archivos desde Drive
   !cp /content/drive/MyDrive/phase1/train.json data/
   !cp /content/drive/MyDrive/phase1/validation.json data/
   ```

### OpciÃ³n 3: Usar Directamente desde Drive

En el notebook, modifica la funciÃ³n `load_data()`:
```python
def load_data():
    train_path = '/content/drive/MyDrive/latin_translator_phase1/train.json'
    val_path = '/content/drive/MyDrive/latin_translator_phase1/validation.json'
    # ... resto del cÃ³digo
```

---

## âš ï¸ Importante: Calidad de los Datos

Los datos actuales son **de ejemplo** (1,000 pares repetidos).

### Para Entrenamiento Real:

Necesitas **20,000-30,000 pares Ãºnicos**. Opciones:

#### A. Descargar Vulgata Completa

1. Ve a: https://www.sacred-texts.com/bib/vul/
2. Descarga el texto completo
3. Busca traducciÃ³n espaÃ±ola (Reina-Valera, NÃ¡car-Colunga)
4. Usa un script de alineaciÃ³n

#### B. Usar OPUS Corpus

1. Ve a: https://opus.nlpl.eu/
2. Busca "Latin-Spanish"
3. Descarga formato Moses o TMX
4. Convierte a JSON

#### C. Perseus Digital Library

1. Ve a: https://www.perseus.tufts.edu/hopper/
2. Descarga textos clÃ¡sicos con traducciones
3. Extrae pares manualmente o con script

---

## ğŸ¯ RecomendaciÃ³n

### Para Probar el Sistema (AHORA):
âœ… Usa los archivos actuales (1,018 pares)
- Tiempo de entrenamiento: ~30 minutos
- BLEU esperado: ~15-20 (bajo, pero funcional para prueba)
- **Objetivo**: Verificar que todo funciona

### Para Modelo Real (DESPUÃ‰S):
ğŸ“¥ Consigue corpus de 20,000-30,000 pares
- Tiempo de entrenamiento: ~8-12 horas
- BLEU esperado: ~30-35 (bueno)
- **Objetivo**: Modelo Ãºtil para producciÃ³n

---

## ğŸ“ PrÃ³ximos Pasos

1. **Ahora**: Prueba el entrenamiento con datos actuales
   - Sube archivos a Colab
   - Ejecuta notebook
   - Verifica que funciona

2. **Luego**: Consigue corpus mÃ¡s grande
   - Descarga Vulgata completa
   - Re-ejecuta script de preparaciÃ³n
   - Re-entrena modelo

---

## ğŸ†˜ Si Necesitas Ayuda

- **Ver datos**: `cat data/training_corpus/phase1/train.json | head -20`
- **Contar pares**: `wc -l data/training_corpus/phase1/train.json`
- **EstadÃ­sticas**: `cat data/training_corpus/phase1/stats.json`

---

**Â¿Listo para entrenar?** ğŸš€

Los archivos estÃ¡n en `data/training_corpus/phase1/`. SÃºbelos a Colab y ejecuta el notebook.
